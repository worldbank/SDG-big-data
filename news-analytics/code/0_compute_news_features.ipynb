{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes as inputs news articles focusing on a specific country and compute the sentiment associated with the article. \n",
    "\n",
    "Our dataset of news comes from Factiva.com. Articles are indexed using region and subject tags. Each article is annotated with topics and geographic tags generated by Factiva using a proprietary algorithm. Note that an article can be tagged with multiple locations and topics. \n",
    "\n",
    "We focused on English articles published by Reuters between 1991 and 2015 and tagged with either `economic news` or `financial market news` as well as with one of the 25 countries in our sample (9 AE and 16 EM). Overall, our dataset covers a wide range of economic topics (e.g. economic policy, government finance, etc.), financial topics (e.g. commodity markets, equity markets, forex, etc.), as well as corporate and political news. \n",
    "\n",
    "Sentiment is measured using a simple dictionary approach based on Loughran and McDonald 2011. To measure news sentiment, we use a `bag-of-words` model, allowing us to reduce complex and multi-dimensional text data into a single number. \n",
    "\n",
    "First, we combine existing lists of positive and negative words found in financial texts by Loughran and McDonald 2011 and in texts related to economic policy by Young and Soroka 2012. We then expand our lists by including the inflections of each word: for example, the word `lose` belongs to the negative list, hence we also include the words `losing`, `loser`, `lost`, `loss`, etc, leading to a final list of 7,217 negative words and 3,250 positive words. \n",
    "\n",
    "Next, we define the sentiment of an article $j$ as:\n",
    "$$ s_{j} = \\dfrac{\\sum_{i} w_{ij} p_{ij} - \\sum_{i} w_{ij} n_{ij}}{\\sum_{i} w_{ij} t_{ij}} $$\n",
    "where $p_{ij}$ is the number of occurrences of positive word $i$ in article $j$, $n_{ij}$ is the number of occurrences of negative word $i$ in article $j$, $t_{ij}$ is the number of occurrences of word $i$ in article $j$, and $w_{ij}$ is the weight associated with word $i$ in article $j$. \n",
    "\n",
    "In our baseline estimates, we take $w_{ij} = 1$, allowing each word to contribute to the sentiment measure proportionally to its frequency of occurrence. In a robustness check, we let each word contribute to the sentiment measure proportionally to its `Term Frequency–Inverse Document Frequency` (TF-IDF, Manning 2010) by taking:\n",
    "$$ w_{ij} = \\log\\left(\\frac{N}{N_{i}}\\right) $$\n",
    "where $N$ is the number of articles in the corpus and $N_{i}$ is the number of articles in which word $i$ is present. Hence, this weighting smoothes out differences in word frequency naturally occurring in the English language by giving more weight to words that appear more rarely across documents. It is well established that the distribution of words in the English language follows a power law. For a broader discussion on power laws in Economics, see Gabaix 2016. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from timeit import default_timer as timer\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data='/scratch/spf248/news/data'\n",
    "\n",
    "filenames_snapshots=[\n",
    "'eeocwhc7sy.pkl.xz', # 2016_2019_25_countries\n",
    "'vynzboapen.pkl.xz', # 2019_2019_25_countries\n",
    "'c35plzarij.pkl.xz', # 1991_2019_remaining_countries\n",
    "'644qmwwrwf.pkl.xz', # 2019_2020\n",
    "'lnl7ntre52.pkl.xz', # 2020_2020\n",
    "]\n",
    "\n",
    "filenames_bulk=[\n",
    "'reuters-econ-fin-mkt-25-countries-1991-1996.pkl',\n",
    "'reuters-econ-fin-mkt-25-countries-1991-2015.pkl.xz',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load snapshot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Data...\n",
      "\n",
      "eeocwhc7sy.pkl.xz\n",
      "vynzboapen.pkl.xz\n",
      "c35plzarij.pkl.xz\n",
      "644qmwwrwf.pkl.xz\n",
      "lnl7ntre52.pkl.xz\n",
      "Done in 118 sec\n"
     ]
    }
   ],
   "source": [
    "print('Import Data...\\n')\n",
    "start = timer()\n",
    "\n",
    "for filename in filenames_snapshots:\n",
    "    print(filename)\n",
    "    dfs[filename]=pd.read_pickle(os.path.join(path_to_data,filename))\n",
    "    \n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Snapshot Data...\n",
      "\n",
      "eeocwhc7sy.pkl.xz\n",
      "vynzboapen.pkl.xz\n",
      "c35plzarij.pkl.xz\n",
      "644qmwwrwf.pkl.xz\n",
      "lnl7ntre52.pkl.xz\n",
      "Done in 14 sec\n"
     ]
    }
   ],
   "source": [
    "print('Clean Snapshot Data...\\n')\n",
    "start = timer()\n",
    "\n",
    "def clean_snapshot_data(df):\n",
    "    df.rename(columns={'region_codes_to_label':'regions',\n",
    "                       'subject_codes_to_label':'subjects',\n",
    "                       'publication_datetime':'date'},inplace=True)\n",
    "    df['full_text']=\\\n",
    "    df['title'].replace(np.nan,'')+' '+\\\n",
    "    df['snippet'].replace(np.nan,'')+' '+\\\n",
    "    df['body'].replace(np.nan,'')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop([x for x in df.columns if x not in ['an','date','regions','subjects','full_text']],1,inplace=True)\n",
    "\n",
    "for filename in filenames_snapshots:\n",
    "    print(filename)\n",
    "    clean_snapshot_data(dfs[filename])\n",
    "        \n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load bulk dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Data...\n",
      "\n",
      "reuters-econ-fin-mkt-25-countries-1991-1996.pkl\n",
      "reuters-econ-fin-mkt-25-countries-1991-2015.pkl.xz\n",
      "Done in 182 sec\n"
     ]
    }
   ],
   "source": [
    "print('Import Data...\\n')\n",
    "start = timer()\n",
    "\n",
    "for filename in filenames_bulk:\n",
    "    print(filename)\n",
    "    dfs[filename]=pd.read_pickle(os.path.join(path_to_data,filename))\n",
    "    \n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Bulk Data...\n",
      "\n",
      "reuters-econ-fin-mkt-25-countries-1991-1996.pkl\n",
      "reuters-econ-fin-mkt-25-countries-1991-2015.pkl.xz\n",
      "Done in 63 sec\n"
     ]
    }
   ],
   "source": [
    "print('Clean Bulk Data...\\n')\n",
    "start = timer()\n",
    "\n",
    "def clean_bulk_data(df_old):\n",
    "    \n",
    "    df=df_old.copy()\n",
    "    \n",
    "    df.rename(columns={'id':'an'},inplace=True)\n",
    "\n",
    "    df['full_text']=\\\n",
    "    df['headline'].replace(np.nan,'')+' '+\\\n",
    "    df['leading paragraph'].replace(np.nan,'')+' '+\\\n",
    "    df['text'].replace(np.nan,'')\n",
    "\n",
    "    if 'hour ET' in df.columns and 'minute' in df.columns:\n",
    "        df['date']=pd.NaT\n",
    "        idx1=df[['year','month','day','hour ET','minute']].dropna().index\n",
    "        df.loc[idx1,'date']=pd.to_datetime(df.loc[idx1,['year','month','day','hour ET','minute']].rename(columns={'hour ET':'hour'}))\n",
    "        idx2=df.loc[~df.index.isin(idx1)].index\n",
    "        df.loc[idx2,'date']=pd.to_datetime(df.loc[idx2,['year','month','day']])\n",
    "    else:\n",
    "        df['date']=pd.to_datetime(df[['year','month','day']])\n",
    "\n",
    "    for tags in ['regions','subjects']:\n",
    "        df = df.loc[(~df[tags].isnull())].copy()\n",
    "        df[tags]=df[tags].apply(lambda x:[y.split(':')[1].strip() for y in x],1)\n",
    "\n",
    "    df.drop([x for x in df.columns if x not in ['an','date','regions','subjects','full_text']],1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "for filename in filenames_bulk:\n",
    "    print(filename)\n",
    "    dfs[filename]=clean_bulk_data(dfs[filename])\n",
    "        \n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge...\n",
      "\n",
      "# Articles: 7683019\n",
      "# Articles: 6751733\n",
      "Done in 13 sec\n"
     ]
    }
   ],
   "source": [
    "print('Merge...\\n')\n",
    "start = timer()\n",
    "\n",
    "df = pd.concat([v for k,v in dfs.items()],sort=True)\n",
    "del dfs\n",
    "print('# Articles:', df.shape[0])\n",
    "\n",
    "df.drop_duplicates('an',inplace=True)\n",
    "df.set_index('an',inplace=True)\n",
    "df.sort_values(by='date',inplace=True)\n",
    "print('# Articles:', df.shape[0])\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         6751733\n",
       "full_text    6751733\n",
       "regions      6751733\n",
       "subjects     6751733\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>full_text</th>\n",
       "      <th>regions</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LBA0000020201115egbf00kr9</th>\n",
       "      <td>2020-11-15 14:23:17</td>\n",
       "      <td>IMF MISSION WILL CONTINUE VIRTUAL WORKING MEET...</td>\n",
       "      <td>[Argentina, Developing Economies, Latin Americ...</td>\n",
       "      <td>[Top Wire News, Government Borrowing, Governme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBA0000020201115egbf00lj1</th>\n",
       "      <td>2020-11-15 14:48:31</td>\n",
       "      <td>Member of IMF team in Argentina tests positive...</td>\n",
       "      <td>[Argentina, Buenos Aires, Developing Economies...</td>\n",
       "      <td>[Top Wire News, Government Borrowing, Outbreak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBA0000020201115egbf00rut</th>\n",
       "      <td>2020-11-15 18:30:13</td>\n",
       "      <td>Asia Morning Call-Global Markets   ",
       "    Nov 16 ...</td>\n",
       "      <td>[China, Japan, Dalian, South Korea, United Sta...</td>\n",
       "      <td>[SARS/MERS Viruses, Outbreaks/Epidemics, Equit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBA0000020201115egbf00wvd</th>\n",
       "      <td>2020-11-15 20:50:19</td>\n",
       "      <td>UPDATE 1-Asia Morning Call-Global Markets   ",
       "  ...</td>\n",
       "      <td>[China, Japan, South Korea, Dalian, United Sta...</td>\n",
       "      <td>[SARS/MERS Viruses, Outbreaks/Epidemics, Forei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBA0000020201115egbf00x99</th>\n",
       "      <td>2020-11-15 21:00:00</td>\n",
       "      <td>Risk of German recession this winter rises, st...</td>\n",
       "      <td>[Germany, DACH Countries, European Union Count...</td>\n",
       "      <td>[Economic News, Facility Openings, SARS/MERS V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         date  \\\n",
       "an                                              \n",
       "LBA0000020201115egbf00kr9 2020-11-15 14:23:17   \n",
       "LBA0000020201115egbf00lj1 2020-11-15 14:48:31   \n",
       "LBA0000020201115egbf00rut 2020-11-15 18:30:13   \n",
       "LBA0000020201115egbf00wvd 2020-11-15 20:50:19   \n",
       "LBA0000020201115egbf00x99 2020-11-15 21:00:00   \n",
       "\n",
       "                                                                   full_text  \\\n",
       "an                                                                             \n",
       "LBA0000020201115egbf00kr9  IMF MISSION WILL CONTINUE VIRTUAL WORKING MEET...   \n",
       "LBA0000020201115egbf00lj1  Member of IMF team in Argentina tests positive...   \n",
       "LBA0000020201115egbf00rut  Asia Morning Call-Global Markets  \n",
       "    Nov 16 ...   \n",
       "LBA0000020201115egbf00wvd  UPDATE 1-Asia Morning Call-Global Markets  \n",
       "  ...   \n",
       "LBA0000020201115egbf00x99  Risk of German recession this winter rises, st...   \n",
       "\n",
       "                                                                     regions  \\\n",
       "an                                                                             \n",
       "LBA0000020201115egbf00kr9  [Argentina, Developing Economies, Latin Americ...   \n",
       "LBA0000020201115egbf00lj1  [Argentina, Buenos Aires, Developing Economies...   \n",
       "LBA0000020201115egbf00rut  [China, Japan, Dalian, South Korea, United Sta...   \n",
       "LBA0000020201115egbf00wvd  [China, Japan, South Korea, Dalian, United Sta...   \n",
       "LBA0000020201115egbf00x99  [Germany, DACH Countries, European Union Count...   \n",
       "\n",
       "                                                                    subjects  \n",
       "an                                                                            \n",
       "LBA0000020201115egbf00kr9  [Top Wire News, Government Borrowing, Governme...  \n",
       "LBA0000020201115egbf00lj1  [Top Wire News, Government Borrowing, Outbreak...  \n",
       "LBA0000020201115egbf00rut  [SARS/MERS Viruses, Outbreaks/Epidemics, Equit...  \n",
       "LBA0000020201115egbf00wvd  [SARS/MERS Viruses, Outbreaks/Epidemics, Forei...  \n",
       "LBA0000020201115egbf00x99  [Economic News, Facility Openings, SARS/MERS V...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strong\n",
      "positive\n",
      "negative\n",
      "uncertainty\n",
      "weak\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(path_to_data,'tone2keywords.pkl'),'rb') as f:\n",
    "    tone2keywords = pickle.load(f)\n",
    "    \n",
    "for name in tone2keywords:\n",
    "    print(name)\n",
    "    tone2keywords[name] = tone2keywords[name].set_index('word')['IDF'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(idx,data=df['full_text'],tones=list(tone2keywords)):\n",
    "    \n",
    "    # Split into words and remove non-letter characters\n",
    "    tokens = re.sub(\"[^a-zA-Z]\",\" \", data.loc[idx].lower()).split()\n",
    "    \n",
    "    # Return Words and Their Count\n",
    "    counter = collections.Counter(tokens)\n",
    "\n",
    "    # Word Count\n",
    "    T = sum(counter.values())\n",
    "\n",
    "    values = [T]\n",
    "    index  = ['# words']\n",
    "\n",
    "    for tone in sorted(tones):\n",
    "\n",
    "        # Tonal Words In the Text\n",
    "        words = list(set(counter.keys())&set(tone2keywords[tone].keys()))\n",
    "\n",
    "        if words:\n",
    "\n",
    "            # Tonal Words Counts\n",
    "            counts = itemgetter(*words)(counter)\n",
    "\n",
    "            # Tonal Words IDFs\n",
    "            idfs = itemgetter(*words)(tone2keywords[tone])\n",
    "\n",
    "            if len(words) > 1:\n",
    "                tf = sum(counts)/T\n",
    "            else:\n",
    "                tf = counts/T\n",
    "                \n",
    "            tfidf = np.dot(counts,idfs)/T\n",
    "\n",
    "        else:\n",
    "\n",
    "            tf = 0\n",
    "            tfidf  = 0\n",
    "\n",
    "        values.append(tf)\n",
    "        index.append('% '+tone)\n",
    "\n",
    "        values.append(tfidf)\n",
    "        index.append('% '+tone+' tfidf')\n",
    "        \n",
    "    return pd.Series(values,index=index,name=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Sentiment...\n",
      "\n",
      "Done In 147 Sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Compute Sentiment...\\n\")\n",
    "start = timer()\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    sentiments = pd.DataFrame(pool.map(get_counts, df.index))\n",
    "    \n",
    "end = timer()\n",
    "print(\"Done In\", round(end - start),\"Sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># words</th>\n",
       "      <th>% negative</th>\n",
       "      <th>% negative tfidf</th>\n",
       "      <th>% positive</th>\n",
       "      <th>% positive tfidf</th>\n",
       "      <th>% strong</th>\n",
       "      <th>% strong tfidf</th>\n",
       "      <th>% uncertainty</th>\n",
       "      <th>% uncertainty tfidf</th>\n",
       "      <th>% weak</th>\n",
       "      <th>% weak tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj5r010vk</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj5t011pc</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.041433</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.041433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj6100vhg</th>\n",
       "      <td>188.0</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.164103</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.080317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj6100vdc</th>\n",
       "      <td>223.0</td>\n",
       "      <td>0.022422</td>\n",
       "      <td>0.159844</td>\n",
       "      <td>0.013453</td>\n",
       "      <td>0.051110</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.020037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj6100vcl</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.254071</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.144083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           # words  % negative  % negative tfidf  % positive  \\\n",
       "lba0000020011204dj5r010vk     54.0    0.000000          0.000000    0.000000   \n",
       "lba0000020011204dj5t011pc     76.0    0.000000          0.000000    0.000000   \n",
       "lba0000020011204dj6100vhg    188.0    0.031915          0.164103    0.015957   \n",
       "lba0000020011204dj6100vdc    223.0    0.022422          0.159844    0.013453   \n",
       "lba0000020011204dj6100vcl     88.0    0.045455          0.254071    0.034091   \n",
       "\n",
       "                           % positive tfidf  % strong  % strong tfidf  \\\n",
       "lba0000020011204dj5r010vk          0.000000  0.000000        0.000000   \n",
       "lba0000020011204dj5t011pc          0.000000  0.000000        0.000000   \n",
       "lba0000020011204dj6100vhg          0.080317  0.000000        0.000000   \n",
       "lba0000020011204dj6100vdc          0.051110  0.004484        0.020037   \n",
       "lba0000020011204dj6100vcl          0.144083  0.000000        0.000000   \n",
       "\n",
       "                           % uncertainty  % uncertainty tfidf    % weak  \\\n",
       "lba0000020011204dj5r010vk       0.000000             0.000000  0.000000   \n",
       "lba0000020011204dj5t011pc       0.013158             0.041433  0.013158   \n",
       "lba0000020011204dj6100vhg       0.000000             0.000000  0.000000   \n",
       "lba0000020011204dj6100vdc       0.000000             0.000000  0.000000   \n",
       "lba0000020011204dj6100vcl       0.000000             0.000000  0.000000   \n",
       "\n",
       "                           % weak tfidf  \n",
       "lba0000020011204dj5r010vk      0.000000  \n",
       "lba0000020011204dj5t011pc      0.041433  \n",
       "lba0000020011204dj6100vhg      0.000000  \n",
       "lba0000020011204dj6100vdc      0.000000  \n",
       "lba0000020011204dj6100vcl      0.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocode regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions...\n",
      "\n",
      "Done in 17 sec\n"
     ]
    }
   ],
   "source": [
    "print('Regions...\\n')\n",
    "start = timer()\n",
    "\n",
    "regions = df['regions'].explode().value_counts()\n",
    "regions = regions.rename('n_obs').reset_index().rename(columns={'index':'region'})\n",
    "regions.to_csv(os.path.join(path_to_data,'regions_'+datetime.today().strftime('%m%Y')+'.csv'))\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>n_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2661597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emerging Market Countries</td>\n",
       "      <td>2329458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North America</td>\n",
       "      <td>2210742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Western Europe</td>\n",
       "      <td>2051720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>2032726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      region    n_obs\n",
       "0                     Europe  2661597\n",
       "1  Emerging Market Countries  2329458\n",
       "2              North America  2210742\n",
       "3             Western Europe  2051720\n",
       "4              United States  2032726"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_geocoded = pd.read_csv(os.path.join(path_to_data,'regions_geocoded_'+datetime.today().strftime('%m%Y')+'.csv'),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2661597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emerging Market Countries</td>\n",
       "      <td>2329458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North America</td>\n",
       "      <td>2210742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Western Europe</td>\n",
       "      <td>2051720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>2032726</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      region    n_obs        country  country_code\n",
       "0                     Europe  2661597            NaN             0\n",
       "1  Emerging Market Countries  2329458            NaN             0\n",
       "2              North America  2210742            NaN             0\n",
       "3             Western Europe  2051720            NaN             0\n",
       "4              United States  2032726  United States             1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_geocoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions...\n",
      "\n",
      "# Articles: 6751733\n",
      "Done In 15 Sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Regions...\\n\")\n",
    "start = timer()\n",
    "\n",
    "# List of country tags\n",
    "regions2countries = df['regions'].explode().rename('region').reset_index().merge(regions_geocoded[['region','country']]).dropna().groupby('an')['country'].apply(lambda x: sorted(set(x)))\n",
    "print('# Articles with country tags:', regions2countries.shape[0])\n",
    "\n",
    "end = timer()\n",
    "print(\"Done In\", round(end - start),\"Sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine news features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([df[['date','subjects']],regions2countries,sentiments[['# words','% negative','% positive']]],1).sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          6751733\n",
       "country       6493433\n",
       "subjects      6751733\n",
       "# words       6751733\n",
       "% negative    6751733\n",
       "% positive    6751733\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>subjects</th>\n",
       "      <th># words</th>\n",
       "      <th>% negative</th>\n",
       "      <th>% positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj5r010vk</th>\n",
       "      <td>1987-05-27</td>\n",
       "      <td>[Taiwan]</td>\n",
       "      <td>[Output/Production, Marketing, Corporate/Indus...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj5t011pc</th>\n",
       "      <td>1987-05-29</td>\n",
       "      <td>[Taiwan]</td>\n",
       "      <td>[Economic Performance/Indicators, Public Secto...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj6100vf7</th>\n",
       "      <td>1987-06-01</td>\n",
       "      <td>[Singapore]</td>\n",
       "      <td>[Debt/Bond Markets, Commodity/Financial Market...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj6100vd5</th>\n",
       "      <td>1987-06-01</td>\n",
       "      <td>[Australia]</td>\n",
       "      <td>[Economic Performance/Indicators, Money Supply...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lba0000020011204dj6100vdn</th>\n",
       "      <td>1987-06-01</td>\n",
       "      <td>[Sri Lanka]</td>\n",
       "      <td>[Economic Performance/Indicators, Public Secto...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date      country  \\\n",
       "lba0000020011204dj5r010vk 1987-05-27     [Taiwan]   \n",
       "lba0000020011204dj5t011pc 1987-05-29     [Taiwan]   \n",
       "lba0000020011204dj6100vf7 1987-06-01  [Singapore]   \n",
       "lba0000020011204dj6100vd5 1987-06-01  [Australia]   \n",
       "lba0000020011204dj6100vdn 1987-06-01  [Sri Lanka]   \n",
       "\n",
       "                                                                    subjects  \\\n",
       "lba0000020011204dj5r010vk  [Output/Production, Marketing, Corporate/Indus...   \n",
       "lba0000020011204dj5t011pc  [Economic Performance/Indicators, Public Secto...   \n",
       "lba0000020011204dj6100vf7  [Debt/Bond Markets, Commodity/Financial Market...   \n",
       "lba0000020011204dj6100vd5  [Economic Performance/Indicators, Money Supply...   \n",
       "lba0000020011204dj6100vdn  [Economic Performance/Indicators, Public Secto...   \n",
       "\n",
       "                           # words  % negative  % positive  \n",
       "lba0000020011204dj5r010vk     54.0    0.000000    0.000000  \n",
       "lba0000020011204dj5t011pc     76.0    0.000000    0.000000  \n",
       "lba0000020011204dj6100vf7    128.0    0.000000    0.015625  \n",
       "lba0000020011204dj6100vd5     96.0    0.010417    0.010417  \n",
       "lba0000020011204dj6100vdn     32.0    0.000000    0.031250  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save...\n",
      "\n",
      "Done In 20 Sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Save...\\n\")\n",
    "start = timer()\n",
    "\n",
    "features.to_pickle(os.path.join(path_to_data,'news_features_'+datetime.today().strftime('%m%Y')+'.pkl'))\n",
    "\n",
    "end = timer()\n",
    "print(\"Done In\", round(end - start),\"Sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
